{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as  sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscoe_df = pd.read_csv('TPA_Datasets.csv')\n",
    "viscoe_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=viscoe_df, x='TPA_Label')  #visualise data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscoe_df.columns\n",
    "\n",
    "# Select features\n",
    "feature_df = viscoe_df[['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ',\n",
    "       'Glucose']]\n",
    "\n",
    "# Independent variable (features)\n",
    "X = np.asarray(feature_df)\n",
    "\n",
    "# Dependent variable (target)\n",
    "y = np.asarray(viscoe_df['TPA_Label'])\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Impute missing values using KNNImputer\n",
    "nan = np.nan\n",
    "imputer = KNNImputer(n_neighbors=6, weights=\"uniform\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X = feature_df = X_imputed\n",
    "\n",
    "print(\"X values after KNN imputation:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count samples in each label before resampling\n",
    "unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "print(\"Label counts before resampling:\")\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(\"Label {}: {}\".format(label, count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE(random_state=6)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Count samples in each label after resampling\n",
    "unique_labels_resampled, label_counts_resampled = np.unique(y_resampled, return_counts=True)\n",
    "print(\"\\nLabel counts after resampling:\")\n",
    "for label, count in zip(unique_labels_resampled, label_counts_resampled):\n",
    "    print(\"Label {}: {}\".format(label, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train and test with 8 classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stratified K-fold CV  &  RANDOM FOREST CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Feature Scaling for input features.\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "  \n",
    "# Create RF classifier object.\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf_rf_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "  \n",
    "for train_index, test_index in skf_rf_classifier.split(X, y):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    lst_accu_stratified.append(rf_classifier.score(X_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "\n",
    "# RANDOM FOREST - IMPORTANT FEATURE\n",
    "\n",
    "importance_rf_classifier = rf_classifier.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance_rf_classifier):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "\n",
    "\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(len(importance_rf_classifier)), importance_rf_classifier)\n",
    "plt.title(\"RF - Feature Importance\")\n",
    "plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ROC CURVE for Random Forest Classifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_rf = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_rf_classifier.split(X_scaled, y_resampled)):\n",
    "    rf_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    \n",
    "    # Plot ROC curve for each fold\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        rf_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_rf_classifier.n_splits - 1),\n",
    "    )\n",
    "    \n",
    "    interp_tpr = np.interp(mean_fpr_rf, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "mean_tpr_rf = np.mean(tprs, axis=0)\n",
    "mean_tpr_rf[-1] = 1.0\n",
    "mean_auc_rf = auc(mean_fpr_rf, mean_tpr_rf)\n",
    "std_auc_rf = np.std(aucs)\n",
    "\n",
    "ax.plot(\n",
    "    mean_fpr_rf,\n",
    "    mean_tpr_rf,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - RF (AUC_RF = %0.2f $\\pm$ %0.2f)\" % (mean_auc_rf, std_auc_rf),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_rf + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_rf - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(\n",
    "    mean_fpr_rf,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - RF\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Stratified K-fold CV  &  K-nearest Neighbor CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean, stdev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=6)\n",
    "skf_knn_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "\n",
    "for train_index, test_index in skf_knn_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    knn_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = knn_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = knn_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:', min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:', mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(importance_rf_classifier):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"KNN - Feature Importance\")\n",
    "    plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_knn = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_knn_classifier.split(X_scaled, y_resampled)):\n",
    "    knn_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        knn_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_knn_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_knn, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "mean_tpr_knn = np.mean(tprs, axis=0)\n",
    "mean_tpr_knn[-1] = 1.0\n",
    "mean_auc_knn = auc(mean_fpr_knn, mean_tpr_knn)\n",
    "std_auc_knn = np.std(aucs)\n",
    "\n",
    "ax.plot(\n",
    "    mean_fpr_knn,\n",
    "    mean_tpr_knn,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - KNN (AUC_KNN = %0.2f $\\pm$ %0.2f)\" % (mean_auc_knn, std_auc_knn),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_knn + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_knn - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(\n",
    "    mean_fpr_knn,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - KNN\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stratified K-fold CV  &  Support Vector Machine CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean, stdev\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "svm_classifier = SVC(kernel='linear', C=1)\n",
    "skf_svm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_svm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    svm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = svm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    feature_importance_scores = dict(enumerate(svm_classifier.coef_[0]))\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value / total_score for key, value in feature_importance_scores.items()}\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified) * 100, '%')\n",
    "    print('\\nMinimum Accuracy:', min(lst_accu_stratified) * 100, '%')\n",
    "    print('\\nOverall Accuracy:', mean(lst_accu_stratified) * 100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i, v in enumerate(importance_rf_classifier):\n",
    "        print('Feature: %0d, Score: %.5f' % (i, v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"SVM - Feature Importance\")\n",
    "    plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_svm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_svm_classifier.split(X_scaled, y_resampled)):\n",
    "    svm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(svm_classifier, X_scaled[test], y_resampled[test], name=f\"Fold {fold + 1}\", alpha=0.3, lw=1, ax=ax, plot_chance_level=(fold == skf_svm_classifier.n_splits - 1))\n",
    "    interp_tpr = np.interp(mean_fpr_svm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_svm = np.mean(tprs, axis=0)\n",
    "mean_tpr_svm[-1] = 1.0\n",
    "mean_auc_svm = auc(mean_fpr_svm, mean_tpr_svm)\n",
    "std_auc_svm = np.std(aucs)\n",
    "ax.plot(mean_fpr_svm, mean_tpr_svm, color=\"b\", label=r\"Mean ROC - SVM (AUC_SVM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_svm, std_auc_svm), lw=2, alpha=0.8)\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_svm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_svm - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr_svm, tprs_lower, tprs_upper, color=\"grey\", alpha=0.2, label=r\"$\\pm$ 1 std. dev.\")\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", title=f\"Mean ROC curve - SVM\")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Stratified K-fold CV  &  Decision Tree CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statistics import mean, stdev\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "skf_dt_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_dt_classifier.split(X_resampled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_resampled[train_index], X_resampled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    dt_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = dt_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    feature_importance_scores_fold = dt_classifier.feature_importances_\n",
    "    for i, score in enumerate(feature_importance_scores_fold):\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + score\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('Maximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified)*100, '%')\n",
    "    print('Minimum Accuracy:', min(lst_accu_stratified)*100, '%')\n",
    "    print('Overall Accuracy:', mean(lst_accu_stratified)*100, '%')\n",
    "    print('Standard Deviation is:', stdev(lst_accu_stratified))\n",
    "    print(\"Feature Importance Scores:\")\n",
    "    for i,v in enumerate(importance_rf_classifier):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"DT - Feature Importance\")\n",
    "    plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_dt = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_dt_classifier.split(X_scaled, y_resampled)):\n",
    "    dt_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        dt_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_dt_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_dt, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_dt = np.mean(tprs, axis=0)\n",
    "mean_tpr_dt[-1] = 1.0\n",
    "mean_auc_dt = auc(mean_fpr_dt, mean_tpr_dt)\n",
    "std_auc_dt = np.std(aucs)\n",
    "ax.plot(mean_fpr_dt, mean_tpr_dt, color=\"b\", label=r\"Mean ROC - DT (AUC_DT = %0.2f $\\pm$ %0.2f)\" % (mean_auc_dt, std_auc_dt), lw=2, alpha=0.8)\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_dt + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_dt - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr_dt, tprs_lower, tprs_upper, color=\"grey\", alpha=0.2, label=r\"$\\pm$ 1 std. dev.\")\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", title=f\"Mean ROC curve - DT\")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stratified K-fold CV  &  RF CLASSIFIER + Bagging Classifier (RFBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean, stdev\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rfbm_classifier = BaggingClassifier(base_rf_classifier, n_estimators=10, random_state=42)\n",
    "skf_rfbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_rfbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rfbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = rfbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = rfbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:', min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:', mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(importance_rf_classifier):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"RFBM - Feature Importance\")\n",
    "    plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_rfbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_rfbm_classifier.split(X_scaled, y_resampled)):\n",
    "    rfbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        rfbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_rfbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_rfbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_rfbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_rfbm[-1] = 1.0\n",
    "mean_auc_rfbm = auc(mean_fpr_rfbm, mean_tpr_rfbm)\n",
    "std_auc_rfbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_rfbm,\n",
    "    mean_tpr_rfbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - RFBM (AUC_RFBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_rfbm, std_auc_rfbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_rfbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_rfbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_rfbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\", \n",
    "    title=f\"Mean ROC curve - RFBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stratified K-fold CV  &  KNN CLASSIFIER + Bagging Classifier (KNNBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statistics import mean, stdev\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_knn_classifier = KNeighborsClassifier(n_neighbors=6)\n",
    "knnbm_classifier = BaggingClassifier(base_knn_classifier, n_estimators=10, random_state=42)\n",
    "skf_knnbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_knnbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    knnbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = knnbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = knnbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(importance_rf_classifier):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"KNNBM - Feature Importance\")\n",
    "    plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_knnbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_knnbm_classifier.split(X_scaled, y_resampled)):\n",
    "    knnbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        knnbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_knnbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_knnbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_knnbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_knnbm[-1] = 1.0\n",
    "mean_auc_knnbm = auc(mean_fpr_knnbm, mean_tpr_knnbm)\n",
    "std_auc_knnbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_knnbm,\n",
    "    mean_tpr_knnbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - KNNBM (AUC_KNNBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_knnbm, std_auc_knnbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_knnbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_knnbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_knnbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - KNNBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Stratified K-fold CV  &  SVM CLASSIFIER + Bagging Classifier (SVMBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statistics import mean, stdev\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svmbm_classifier = BaggingClassifier(base_svm_classifier, n_estimators=10, random_state=42)\n",
    "skf_svmbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_svmbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    svmbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = svmbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = svmbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:', min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:', mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i, v in enumerate(feature_importance_scores.values()):\n",
    "        print('Feature: %0d, Score: %.5f' % (i, v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"SVMBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC-AUC\n",
    "\n",
    "from statistics import mean, stdev\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc, RocCurveDisplay\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_svmbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_svmbm_classifier.split(X_scaled, y_resampled)):\n",
    "    svmbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        svmbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_svmbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_svmbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_svmbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_svmbm[-1] = 1.0\n",
    "mean_auc_svmbm = auc(mean_fpr_svmbm, mean_tpr_svmbm)\n",
    "std_auc_svmbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_svmbm,\n",
    "    mean_tpr_svmbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - SVMBM (AUC_SVMBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_svmbm, std_auc_svmbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_svmbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_svmbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_svmbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - SVMBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Stratified K-fold CV  &  Decision Tree CLASSIFIER + Bagging Classifier (DTBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statistics import mean, stdev\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dtbm_classifier = BaggingClassifier(base_dt_classifier, n_estimators=10, random_state=42)\n",
    "skf_dtbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_dtbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    dtbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = dtbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = dtbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "if lst_accu_stratified:\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"DTBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "\n",
    "# 3. ROC-AUC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_dtbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_dtbm_classifier.split(X_scaled, y_resampled)):\n",
    "    dtbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(dtbm_classifier, X_scaled[test], y_resampled[test], name=f\"Fold {fold + 1}\", alpha=0.3, lw=1, ax=ax, plot_chance_level=(fold == skf_dtbm_classifier.n_splits - 1))\n",
    "    interp_tpr = np.interp(mean_fpr_dtbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_dtbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_dtbm[-1] = 1.0\n",
    "mean_auc_dtbm = auc(mean_fpr_dtbm, mean_tpr_dtbm)\n",
    "std_auc_dtbm = np.std(aucs)\n",
    "ax.plot(mean_fpr_dtbm, mean_tpr_dtbm, color=\"b\", label=r\"Mean ROC - DTBM (AUC_DTBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_dtbm, std_auc_dtbm), lw=2, alpha=0.8)\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_dtbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_dtbm - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr_dtbm, tprs_lower, tprs_upper, color=\"grey\", alpha=0.2, label=r\"$\\pm$ 1 std. dev.\")\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", title=f\"Mean ROC curve - DTBM\")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Plot the mean ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(mean_fpr_rf, mean_tpr_rf, color=\"cornflowerblue\", linestyle='dashed', label=f\"ROC - RF (AUC = {mean_auc_rf:.2f} $\\pm$ {std_auc_rf:.2f})\")\n",
    "plt.plot(mean_fpr_knn, mean_tpr_knn, color=\"lightcoral\", linestyle='dashed', label=f\"ROC - KNN (AUC = {mean_auc_knn:.2f} $\\pm$ {std_auc_knn:.2f})\")\n",
    "plt.plot(mean_fpr_svm, mean_tpr_svm, color=\"limegreen\", linestyle='dashed', label=f\"ROC - SVM (AUC = {mean_auc_svm:.2f} $\\pm$ {std_auc_svm:.2f})\")\n",
    "plt.plot(mean_fpr_dt, mean_tpr_dt, color=\"dimgrey\", linestyle='dashed', label=f\"ROC - DT (AUC = {mean_auc_dt:.2f} $\\pm$ {std_auc_dt:.2f})\")\n",
    "\n",
    "plt.plot(mean_fpr_rfbm, mean_tpr_rfbm, color=\"cornflowerblue\", label=f\"ROC - RFBM (AUC = {mean_auc_rfbm:.2f} $\\pm$ {std_auc_rfbm:.2f})\")\n",
    "plt.plot(mean_fpr_knnbm, mean_tpr_knnbm, color=\"lightcoral\", label=f\"ROC - KNNBM (AUC = {mean_auc_knnbm:.2f} $\\pm$ {std_auc_knnbm:.2f})\")\n",
    "plt.plot(mean_fpr_svmbm, mean_tpr_svmbm, color=\"limegreen\", label=f\"ROC - SVMBM (AUC = {mean_auc_svmbm:.2f} $\\pm$ {std_auc_svmbm:.2f})\")\n",
    "plt.plot(mean_fpr_dtbm, mean_tpr_dtbm, color=\"dimgrey\", label=f\"ROC - DTBM (AUC = {mean_auc_dtbm:.2f} $\\pm$ {std_auc_dtbm:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"-.\", color=\"gray\", label=\"Random Classifier\")\n",
    "\n",
    "plt.plot([0, 1], [1, 1], color='black', lw=1, linestyle=':', label='Perfect Classifier')\n",
    "plt.plot([0, 0], [0, 1], color='black', lw=1, linestyle=':')\n",
    "\n",
    "# Set graph properties\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=13)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=13)\n",
    "plt.legend(loc=\"lower right\", fontsize=9.8)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
