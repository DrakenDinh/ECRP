{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import label_binarize, MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, auc, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscoe_df = pd.read_csv('TPA_Datasets.csv')\n",
    "viscoe_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=viscoe_df, x='TPA_Label')  #visualise data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscoe_df.columns\n",
    "\n",
    "# Select features\n",
    "feature_df = viscoe_df[['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']]\n",
    "\n",
    "# Independent variable (features)\n",
    "X = np.asarray(feature_df)\n",
    "\n",
    "# Dependent variable (target)\n",
    "y = np.asarray(viscoe_df['TPA_Label'])\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Impute missing values using KNNImputer\n",
    "nan = np.nan\n",
    "imputer = KNNImputer(n_neighbors=6, weights=\"uniform\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X = feature_df = X_imputed\n",
    "\n",
    "print(\"X values after KNN imputation:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count samples in each label before resampling\n",
    "unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "print(\"Label counts before resampling:\")\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(\"Label {}: {}\".format(label, count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample using SMOTE\n",
    "smote = SMOTE(random_state=6, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Count samples in each label after resampling\n",
    "unique_labels_resampled, label_counts_resampled = np.unique(y_resampled, return_counts=True)\n",
    "print(\"\\nLabel counts after resampling:\")\n",
    "for label, count in zip(unique_labels_resampled, label_counts_resampled):\n",
    "    print(\"Label {}: {}\".format(label, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test with 8 classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stratified K-fold CV  &  RANDOM FOREST CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling for input features.\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "  \n",
    "# Create RF classifier object.\n",
    "rf_classifier = RandomForestClassifier(random_state=42, criterion= 'gini', max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators= 100)\n",
    "\n",
    "\n",
    "# Create StratifiedKFold object.\n",
    "skf_rf_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_rf_stratified = []\n",
    "lst_precision_rf_stratified = []\n",
    "lst_recall_rf_stratified = []\n",
    "  \n",
    "for train_index, test_index in skf_rf_classifier.split(X, y):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    lst_accu_stratified.append(rf_classifier.score(X_test_fold, y_test_fold))\n",
    "    \n",
    "    # Predict on the test fold\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "\n",
    "    # Calculate F1, precision, and recall for the fold\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    lst_f1_rf_stratified.append(f1)\n",
    "    lst_precision_rf_stratified.append(precision)\n",
    "    lst_recall_rf_stratified.append(recall)  \n",
    "    \n",
    "# Print evaluation metrics\n",
    "print('List of F1-scores for RF each fold:', lst_f1_rf_stratified)\n",
    "print('Mean F1-score for RF:', mean(lst_f1_rf_stratified), '±', stdev(lst_f1_rf_stratified))\n",
    "\n",
    "print('List of Precision for RF each fold:', lst_precision_rf_stratified)\n",
    "print('Mean Precision for RF:', mean(lst_precision_rf_stratified), '±', stdev(lst_precision_rf_stratified))\n",
    "\n",
    "print('List of Recall for RF each fold:', lst_recall_rf_stratified)\n",
    "print('Mean Recall for RF:', mean(lst_recall_rf_stratified), '±', stdev(lst_recall_rf_stratified))    \n",
    "\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "\n",
    "# RANDOM FOREST - IMPORTANT FEATURE\n",
    "\n",
    "importance_rf_classifier = rf_classifier.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance_rf_classifier):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# define feature names\n",
    "feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(len(importance_rf_classifier)), importance_rf_classifier)\n",
    "plt.title(\"RF - Feature Importance\")\n",
    "plt.xticks(range(len(importance_rf_classifier)), feature_names, rotation='vertical')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ROC CURVE for Random Forest Classifier\n",
    "# Evaluate model using k-fold CV and plot ROC curve\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_rf = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_rf_classifier.split(X_scaled, y_resampled)):\n",
    "    rf_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    \n",
    "    # Plot ROC curve for each fold\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        rf_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_rf_classifier.n_splits - 1),\n",
    "    )\n",
    "    \n",
    "    interp_tpr = np.interp(mean_fpr_rf, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "# Plot mean ROC curve with variability\n",
    "mean_tpr_rf = np.mean(tprs, axis=0)\n",
    "mean_tpr_rf[-1] = 1.0\n",
    "mean_auc_rf = auc(mean_fpr_rf, mean_tpr_rf)\n",
    "std_auc_rf = np.std(aucs)\n",
    "\n",
    "ax.plot(\n",
    "    mean_fpr_rf,\n",
    "    mean_tpr_rf,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - RF (AUC_RF = %0.2f $\\pm$ %0.2f)\" % (mean_auc_rf, std_auc_rf),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_rf + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_rf - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(\n",
    "    mean_fpr_rf,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - RF\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Stratified K-fold CV  &  K-nearest Neighbor CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=4, algorithm='auto', leaf_size=10, metric='minkowski', p= 4, weights='distance')\n",
    "skf_knn_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_knn_stratified = []\n",
    "lst_precision_knn_stratified = []\n",
    "lst_recall_knn_stratified = []\n",
    "feature_importance_scores = {}\n",
    "\n",
    "for train_index, test_index in skf_knn_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    \n",
    "    knn_classifier.fit(X_train_fold, y_train_fold)\n",
    "    accu_score = knn_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    y_pred_fold_knn = knn_classifier.predict(X_test_fold)\n",
    "    f1_knn = f1_score(y_test_fold, y_pred_fold_knn, average='weighted')\n",
    "    precision_knn = precision_score(y_test_fold, y_pred_fold_knn, average='weighted')\n",
    "    recall_knn = recall_score(y_test_fold, y_pred_fold_knn, average='weighted')\n",
    "    lst_f1_knn_stratified.append(f1_knn)\n",
    "    lst_precision_knn_stratified.append(precision_knn)\n",
    "    lst_recall_knn_stratified.append(recall_knn)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = knn_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "\n",
    "print('List of F1-scores for KNN each fold:', lst_f1_knn_stratified)\n",
    "print('Mean F1-score for KNN:', mean(lst_f1_knn_stratified), '±', stdev(lst_f1_knn_stratified))\n",
    "print('List of Precision for KNN each fold:', lst_precision_knn_stratified)\n",
    "print('Mean Precision for KNN:', mean(lst_precision_knn_stratified), '±', stdev(lst_precision_knn_stratified))\n",
    "print('List of Recall for KNN each fold:', lst_recall_knn_stratified)\n",
    "print('Mean Recall for KNN:', mean(lst_recall_knn_stratified), '±', stdev(lst_recall_knn_stratified)).\n",
    "if lst_accu_stratified:\n",
    "    print('List of possible accuracy:', lst_accu_stratified)\n",
    "    print('Mean Accuracy for KNN:', mean(lst_accu_stratified) * 100, '±', stdev(lst_accu_stratified) * 100)\n",
    "\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(feature_importance_scores):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"KNN - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for KNN Classifier\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_knn = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_knn_classifier.split(X_scaled, y_resampled)):\n",
    "    knn_classifier.fit(X_scaled[train], y_resampled[train])\\\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        knn_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_knn_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_knn, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_knn = np.mean(tprs, axis=0)\n",
    "mean_tpr_knn[-1] = 1.0\n",
    "mean_auc_knn = auc(mean_fpr_knn, mean_tpr_knn)\n",
    "std_auc_knn = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_knn,\n",
    "    mean_tpr_knn,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - KNN (AUC_KNN = %0.2f $\\pm$ %0.2f)\" % (mean_auc_knn, std_auc_knn),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_knn + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_knn - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_knn,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - KNN\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stratified K-fold CV  &  Support Vector Machine CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "svm_classifier = SVC(C=4, kernel='linear', random_state=42)\n",
    "skf_svm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_svm_stratified = []\n",
    "lst_precision_svm_stratified = []\n",
    "lst_recall_svm_stratified = []\n",
    "feature_importance_scores = {}\n",
    "\n",
    "for train_index, test_index in skf_svm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    svm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_svm = svm_classifier.predict(X_test_fold)\n",
    "    accu_score = svm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    f1_svm = f1_score(y_test_fold, y_pred_fold_svm, average='weighted')\n",
    "    precision_svm = precision_score(y_test_fold, y_pred_fold_svm, average='weighted')\n",
    "    recall_svm = recall_score(y_test_fold, y_pred_fold_svm, average='weighted')\n",
    "    lst_f1_svm_stratified.append(f1_svm)\n",
    "    lst_precision_svm_stratified.append(precision_svm)\n",
    "    lst_recall_svm_stratified.append(recall_svm)\n",
    "    feature_importance_scores = dict(enumerate(svm_classifier.coef_[0]))\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value / total_score for key, value in feature_importance_scores.items()}\n",
    "\n",
    "print('List of F1-scores for SVM each fold:', lst_f1_svm_stratified)\n",
    "print('Mean F1-score for SVM:', mean(lst_f1_svm_stratified), '±', stdev(lst_f1_svm_stratified))\n",
    "print('List of Precision for SVM each fold:', lst_precision_svm_stratified)\n",
    "print('Mean Precision for SVM:', mean(lst_precision_svm_stratified), '±', stdev(lst_precision_svm_stratified))\n",
    "print('List of Recall for SVM each fold:', lst_recall_svm_stratified)\n",
    "print('Mean Recall for SVM:', mean(lst_recall_svm_stratified), '±', stdev(lst_recall_svm_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('Mean Accuracy for SVM:', mean(lst_accu_stratified) * 100, '±', stdev(lst_accu_stratified) * 100)\n",
    "if lst_accu_stratified:\n",
    "    print('List of possible accuracy:', lst_accu_stratified)\n",
    "    print('Mean Accuracy for SVM:', mean(lst_accu_stratified) * 100, '±', stdev(lst_accu_stratified) * 100)\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(feature_importance_scores):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"SVM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for SVM Classifier\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_svm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_svm_classifier.split(X_scaled, y_resampled)):\n",
    "    svm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        svm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_svm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_svm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_svm = np.mean(tprs, axis=0)\n",
    "mean_tpr_svm[-1] = 1.0\n",
    "mean_auc_svm = auc(mean_fpr_svm, mean_tpr_svm)\n",
    "std_auc_svm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_svm,\n",
    "    mean_tpr_svm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - SVM (AUC_SVM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_svm, std_auc_svm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_svm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_svm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_svm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - SVM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Stratified K-fold CV  &  Decision Tree CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, ccp_alpha=0.0, criterion='gini', max_depth=None, max_features=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, splitter='best')\n",
    "skf_dt_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_dt_stratified = []\n",
    "lst_precision_dt_stratified = []\n",
    "lst_recall_dt_stratified = []\n",
    "feature_importance_scores = {}\n",
    "\n",
    "for train_index, test_index in skf_dt_classifier.split(X_resampled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_resampled[train_index], X_resampled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    dt_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_dt = dt_classifier.predict(X_test_fold)\n",
    "    f1_dt = f1_score(y_test_fold, y_pred_fold_dt, average='weighted')\n",
    "    precision_dt = precision_score(y_test_fold, y_pred_fold_dt, average='weighted')\n",
    "    recall_dt = recall_score(y_test_fold, y_pred_fold_dt, average='weighted')\n",
    "    lst_f1_dt_stratified.append(f1_dt)\n",
    "    lst_precision_dt_stratified.append(precision_dt)\n",
    "    lst_recall_dt_stratified.append(recall_dt)\n",
    "    accu_score = dt_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    feature_importance_scores_fold = dt_classifier.feature_importances_\n",
    "    for i, score in enumerate(feature_importance_scores_fold):\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + score\n",
    "total_score = sum(feature_importance_scores.values())\n",
    "feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "print('List of F1-scores for Decision Tree each fold:', lst_f1_dt_stratified)\n",
    "print('Mean F1-score for Decision Tree:', mean(lst_f1_dt_stratified), '±', stdev(lst_f1_dt_stratified))\n",
    "print('List of Precision for Decision Tree each fold:', lst_precision_dt_stratified)\n",
    "print('Mean Precision for Decision Tree:', mean(lst_precision_dt_stratified), '±', stdev(lst_precision_dt_stratified))\n",
    "print('List of Recall for Decision Tree each fold:', lst_recall_dt_stratified)\n",
    "print('Mean Recall for Decision Tree:', mean(lst_recall_dt_stratified), '±', stdev(lst_recall_dt_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(feature_importance_scores):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"DT - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for DT Classifier\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_dt = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_dt_classifier.split(X_scaled, y_resampled)):\n",
    "    dt_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        dt_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_dt_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_dt, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_dt = np.mean(tprs, axis=0)\n",
    "mean_tpr_dt[-1] = 1.0\n",
    "mean_auc_dt = auc(mean_fpr_dt, mean_tpr_dt)\n",
    "std_auc_dt = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_dt,\n",
    "    mean_tpr_dt,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - DT (AUC_DT = %0.2f $\\pm$ %0.2f)\" % (mean_auc_dt, std_auc_dt),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_dt + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_dt - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_dt,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - DT\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stratified K-fold CV  &  RF CLASSIFIER + Bagging Classifier (RFBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_rf_classifier = RandomForestClassifier(random_state=42, criterion= 'gini', max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators= 100)\n",
    "rfbm_classifier = BaggingClassifier(base_rf_classifier, n_estimators=10, random_state=42)\n",
    "skf_rfbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_rfbm_stratified = []\n",
    "lst_precision_rfbm_stratified = []\n",
    "lst_recall_rfbm_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_rfbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rfbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_rfbm = rfbm_classifier.predict(X_test_fold)\n",
    "    f1_rfbm = f1_score(y_test_fold, y_pred_fold_rfbm, average='weighted')\n",
    "    precision_rfbm = precision_score(y_test_fold, y_pred_fold_rfbm, average='weighted')\n",
    "    recall_rfbm = recall_score(y_test_fold, y_pred_fold_rfbm, average='weighted')\n",
    "    lst_f1_rfbm_stratified.append(f1_rfbm)\n",
    "    lst_precision_rfbm_stratified.append(precision_rfbm)\n",
    "    lst_recall_rfbm_stratified.append(recall_rfbm)\n",
    "    accu_score = rfbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = rfbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of F1-scores for RFBM each fold:', lst_f1_rfbm_stratified)\n",
    "print('\\nMean F1-score for RFBM:', mean(lst_f1_rfbm_stratified))\n",
    "print('\\nStandard Deviation of F1-score for RFBM:', stdev(lst_f1_rfbm_stratified))\n",
    "print('List of Precision for RFBM each fold:', lst_precision_rfbm_stratified)\n",
    "print('\\nMean Precision:', mean(lst_precision_rfbm_stratified))\n",
    "print('\\nStandard Deviation of Precision RFBM:', stdev(lst_precision_rfbm_stratified))\n",
    "print('List of Recall for RFBM each fold:', lst_recall_rfbm_stratified)\n",
    "print('\\nMean Recall RFBM:', mean(lst_recall_rfbm_stratified))\n",
    "print('\\nStandard Deviation of Recall RFBM:', stdev(lst_recall_rfbm_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(feature_importance_scores):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"RFBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for Random Forest Bagging Classifier\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_rfbm = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_rfbm_classifier.split(X_scaled, y_resampled)):\n",
    "    rfbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        rfbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_rfbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_rfbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_rfbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_rfbm[-1] = 1.0\n",
    "mean_auc_rfbm = auc(mean_fpr_rfbm, mean_tpr_rfbm)\n",
    "std_auc_rfbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_rfbm,\n",
    "    mean_tpr_rfbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - RFBM (AUC_RFBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_rfbm, std_auc_rfbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_rfbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_rfbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_rfbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\", \n",
    "    title=f\"Mean ROC curve - RFBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stratified K-fold CV  &  KNN CLASSIFIER + Bagging Classifier (KNNBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_knn_classifier = KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski', n_neighbors=4, p= 4, weights='distance')\n",
    "knnbm_classifier = BaggingClassifier(base_knn_classifier, n_estimators=10, random_state=42)\n",
    "skf_knnbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_knnbm_stratified = []\n",
    "lst_precision_knnbm_stratified = []\n",
    "lst_recall_knnbm_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_knnbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    knnbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_knnbm = knnbm_classifier.predict(X_test_fold)\n",
    "    f1_knnbm = f1_score(y_test_fold, y_pred_fold_knnbm, average='weighted')\n",
    "    precision_knnbm = precision_score(y_test_fold, y_pred_fold_knnbm, average='weighted')\n",
    "    recall_knnbm = recall_score(y_test_fold, y_pred_fold_knnbm, average='weighted')\n",
    "    lst_f1_knnbm_stratified.append(f1_knnbm)\n",
    "    lst_precision_knnbm_stratified.append(precision_knnbm)\n",
    "    lst_recall_knnbm_stratified.append(recall_knnbm)   \n",
    "    accu_score = knnbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = knnbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of F1-scores for KNNBM each fold:', lst_f1_knnbm_stratified)\n",
    "print('\\nMean F1-score for KNNBM:', mean(lst_f1_knnbm_stratified))\n",
    "print('\\nStandard Deviation of F1-score for KNNBM:', stdev(lst_f1_knnbm_stratified))\n",
    "print('List of Precision for KNNBM each fold:', lst_precision_knnbm_stratified)\n",
    "print('\\nMean Precision:', mean(lst_precision_knnbm_stratified))\n",
    "print('\\nStandard Deviation of Precision KNNBM:', stdev(lst_precision_knnbm_stratified))\n",
    "print('List of Recall for KNNBM each fold:', lst_recall_knnbm_stratified)\n",
    "print('\\nMean Recall KNNBM:', mean(lst_recall_knnbm_stratified))\n",
    "print('\\nStandard Deviation of Recall KNNBM:', stdev(lst_recall_knnbm_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i,v in enumerate(feature_importance_scores):\n",
    "    \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"KNNBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for KNNBM Classifier\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_knnbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_knnbm_classifier.split(X_scaled, y_resampled)):\n",
    "    knnbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        knnbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\", \n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_knnbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_knnbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_knnbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_knnbm[-1] = 1.0\n",
    "mean_auc_knnbm = auc(mean_fpr_knnbm, mean_tpr_knnbm)\n",
    "std_auc_knnbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_knnbm,\n",
    "    mean_tpr_knnbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - KNNBM (AUC_KNNBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_knnbm, std_auc_knnbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_knnbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_knnbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_knnbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - KNNBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Stratified K-fold CV  &  SVM CLASSIFIER + Bagging Classifier (SVMBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_svm_classifier = SVC(C=4, kernel='linear', random_state=42)\n",
    "svmbm_classifier = BaggingClassifier(base_svm_classifier, n_estimators=10, random_state=42)\n",
    "skf_svmbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_svmbm_stratified = []\n",
    "lst_precision_svmbm_stratified = []\n",
    "lst_recall_svmbm_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_svmbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    svmbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_svmbm = svmbm_classifier.predict(X_test_fold)\n",
    "    f1_svmbm = f1_score(y_test_fold, y_pred_fold_svmbm, average='weighted')\n",
    "    precision_svmbm = precision_score(y_test_fold, y_pred_fold_svmbm, average='weighted')\n",
    "    recall_svmbm = recall_score(y_test_fold, y_pred_fold_svmbm, average='weighted')\n",
    "    lst_f1_svmbm_stratified.append(f1_svmbm)\n",
    "    lst_precision_svmbm_stratified.append(precision_svmbm)\n",
    "    lst_recall_svmbm_stratified.append(recall_svmbm)\n",
    "    accu_score = svmbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = svmbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of F1-scores for SVMBM each fold:', lst_f1_svmbm_stratified)\n",
    "print('\\nMean F1-score for SVMBM:', mean(lst_f1_svmbm_stratified), '±', stdev(lst_f1_svmbm_stratified))\n",
    "print('List of Precision for SVMBM each fold:', lst_precision_svmbm_stratified)\n",
    "print('\\nMean Precision:', mean(lst_precision_svmbm_stratified), '±', stdev(lst_precision_svmbm_stratified))\n",
    "print('List of Recall for SVMBM each fold:', lst_recall_svmbm_stratified)\n",
    "print('\\nMean Recall SVMBM:', mean(lst_recall_svmbm_stratified), '±', stdev(lst_recall_svmbm_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i, v in enumerate(feature_importance_scores.values()):\n",
    "        print('Feature: %0d, Score: %.5f' % (i, v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"SVMBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for SVMBM Classifier\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_svmbm = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_svmbm_classifier.split(X_scaled, y_resampled)):\n",
    "    svmbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    # Plot ROC curve for each fold\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        svmbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_svmbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_svmbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_svmbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_svmbm[-1] = 1.0\n",
    "mean_auc_svmbm = auc(mean_fpr_svmbm, mean_tpr_svmbm)\n",
    "std_auc_svmbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_svmbm,\n",
    "    mean_tpr_svmbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - SVMBM (AUC_SVMBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_svmbm, std_auc_svmbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_svmbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_svmbm - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(\n",
    "    mean_fpr_svmbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - SVMBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Stratified K-fold CV  &  Decision Tree CLASSIFIER + Bagging Classifier (DTBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "base_dt_classifier = DecisionTreeClassifier(random_state=42, ccp_alpha=0.0, criterion='gini', max_depth=None, max_features=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, splitter='best')\n",
    "dtbm_classifier = BaggingClassifier(base_dt_classifier, n_estimators=10, random_state=42)\n",
    "skf_dtbm_classifier = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lst_accu_stratified = []\n",
    "lst_f1_dtbm_stratified = []\n",
    "lst_precision_dtbm_stratified = []\n",
    "lst_recall_dtbm_stratified = []\n",
    "feature_importance_scores = {}\n",
    "for train_index, test_index in skf_dtbm_classifier.split(X_scaled, y_resampled):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    dtbm_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold_dtbm = dtbm_classifier.predict(X_test_fold) \n",
    "    f1_dtbm = f1_score(y_test_fold, y_pred_fold_dtbm, average='weighted')\n",
    "    precision_dtbm = precision_score(y_test_fold, y_pred_fold_dtbm, average='weighted')\n",
    "    recall_dtbm = recall_score(y_test_fold, y_pred_fold_dtbm, average='weighted')\n",
    "    lst_f1_dtbm_stratified.append(f1_dtbm)\n",
    "    lst_precision_dtbm_stratified.append(precision_dtbm)\n",
    "    lst_recall_dtbm_stratified.append(recall_dtbm)\n",
    "    accu_score = dtbm_classifier.score(X_test_fold, y_test_fold)\n",
    "    lst_accu_stratified.append(accu_score)\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        perturbed_X_test = X_test_fold.copy()\n",
    "        perturbed_X_test[:, i] = np.random.permutation(perturbed_X_test[:, i])\n",
    "        perturbed_accu_score = dtbm_classifier.score(perturbed_X_test, y_test_fold)\n",
    "        feature_importance_scores[i] = feature_importance_scores.get(i, 0) + (accu_score - perturbed_accu_score)\n",
    "print('List of F1-scores for DTBM each fold:', lst_f1_dtbm_stratified)\n",
    "print('\\nMean F1-score for DTBM:', mean(lst_f1_dtbm_stratified))\n",
    "print('\\nStandard Deviation of F1-score for DTBM:', stdev(lst_f1_dtbm_stratified))\n",
    "print('List of Precision for DTBM each fold:', lst_precision_dtbm_stratified)\n",
    "print('\\nMean Precision:', mean(lst_precision_dtbm_stratified))\n",
    "print('\\nStandard Deviation of Precision DTBM:', stdev(lst_precision_dtbm_stratified))\n",
    "print('List of Recall for DTBM each fold:', lst_recall_dtbm_stratified)\n",
    "print('\\nMean Recall DTBM:', mean(lst_recall_dtbm_stratified))\n",
    "print('\\nStandard Deviation of Recall DTBM:', stdev(lst_recall_dtbm_stratified))\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "if lst_accu_stratified:\n",
    "    print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "          max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nMinimum Accuracy:',\n",
    "          min(lst_accu_stratified)*100, '%')\n",
    "    print('\\nOverall Accuracy:',\n",
    "          mean(lst_accu_stratified)*100, '%')\n",
    "    print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "    total_score = sum(feature_importance_scores.values())\n",
    "    feature_importance_scores = {key: value/total_score for key, value in feature_importance_scores.items()}\n",
    "    print(\"\\nFeature Importance Scores:\")\n",
    "    for i, v in enumerate(feature_importance_scores.values()):\n",
    "        print('Feature: %0d, Score: %.5f' % (i, v))\n",
    "    feature_names = ['beta', 'Ep', 'EDR', 'Age', 'Sex', 'SBP', 'Smoking', 'HDL', 'LDL ', 'Glucose']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(feature_importance_scores.keys(), feature_importance_scores.values())\n",
    "    plt.title(\"DTBM - Feature Importance\")\n",
    "    plt.xticks(range(len(feature_importance_scores)), feature_names, rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No accuracy scores available.\")\n",
    "\n",
    "# ROC CURVE for Decision Tree Bagging Classifier\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr_dtbm = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(skf_dtbm_classifier.split(X_scaled, y_resampled)):\n",
    "    dtbm_classifier.fit(X_scaled[train], y_resampled[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        dtbm_classifier,\n",
    "        X_scaled[test],\n",
    "        y_resampled[test],\n",
    "        name=f\"Fold {fold + 1}\",  # Add 1 to fold for the updated name\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(fold == skf_dtbm_classifier.n_splits - 1),\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr_dtbm, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "mean_tpr_dtbm = np.mean(tprs, axis=0)\n",
    "mean_tpr_dtbm[-1] = 1.0\n",
    "mean_auc_dtbm = auc(mean_fpr_dtbm, mean_tpr_dtbm)\n",
    "std_auc_dtbm = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr_dtbm,\n",
    "    mean_tpr_dtbm,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC - DTBM (AUC_DTBM = %0.2f $\\pm$ %0.2f)\" % (mean_auc_dtbm, std_auc_dtbm),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr_dtbm + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr_dtbm - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr_dtbm,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve - DTBM\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract x and y-axis data from the mean ROC curve\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Plot the mean ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(mean_fpr_rf, mean_tpr_rf, color=\"cornflowerblue\", linestyle='dashed', label=f\"ROC - RF\")\n",
    "plt.plot(mean_fpr_knn, mean_tpr_knn, color=\"lightcoral\", linestyle='dashed', label=f\"ROC - KNN\")\n",
    "plt.plot(mean_fpr_svm, mean_tpr_svm, color=\"limegreen\", linestyle='dashed', label=f\"ROC - SVM\")\n",
    "plt.plot(mean_fpr_dt, mean_tpr_dt, color=\"dimgrey\", linestyle='dashed', label=f\"ROC - DT\")\n",
    "\n",
    "plt.plot(mean_fpr_rfbm, mean_tpr_rfbm, color=\"cornflowerblue\", label=f\"ROC - RFBM\")\n",
    "plt.plot(mean_fpr_knnbm, mean_tpr_knnbm, color=\"lightcoral\", label=f\"ROC - KNNBM\")\n",
    "plt.plot(mean_fpr_svmbm, mean_tpr_svmbm, color=\"limegreen\", label=f\"ROC - SVMBM\")\n",
    "plt.plot(mean_fpr_dtbm, mean_tpr_dtbm, color=\"dimgrey\", label=f\"ROC - DTBM\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"-.\", color=\"gray\", label=\"Random Classifier\")\n",
    "\n",
    "plt.plot([0, 1], [1, 1], color='black', lw=1, linestyle=':', label='Perfect Classifier')\n",
    "plt.plot([0, 0], [0, 1], color='black', lw=1, linestyle=':')\n",
    "\n",
    "# Set graph properties\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=13)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=13)\n",
    "plt.legend(loc=\"lower right\", fontsize=9.8)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
